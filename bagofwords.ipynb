{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['for job', 'hathodawala is', 'is looking', 'looking for',\n",
       "       'thor hathodawala'], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "v = CountVectorizer(ngram_range=(2,2))\n",
    "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "v.get_feature_names_out()\n",
    "# v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Thor ate pizza\",\n",
    "    \"Loki is tall\",\n",
    "    \"Loki is eating pizza\",\n",
    "    \"Talha is a boy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thor eat pizza'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Thor ate pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thor eat pizza', 'Loki tall', 'Loki eat pizza', 'Talha boy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus_processed = [\n",
    "#     preprocess(text) \n",
    "#     for text in corpus\n",
    "# ]\n",
    "\n",
    "corpus_processed=[]\n",
    "for i in corpus:\n",
    "    preocess_text=preprocess(i)\n",
    "    corpus_processed.append(preocess_text)\n",
    "corpus_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 10,\n",
       " 'eat': 1,\n",
       " 'pizza': 6,\n",
       " 'thor eat': 11,\n",
       " 'eat pizza': 2,\n",
       " 'loki': 3,\n",
       " 'tall': 9,\n",
       " 'loki tall': 5,\n",
       " 'loki eat': 4,\n",
       " 'talha': 7,\n",
       " 'boy': 0,\n",
       " 'talha boy': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(ngram_range=(1,2))\n",
    "v.fit(corpus_processed)\n",
    "v.get_feature_names_out()\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['boy', 'eat', 'eat pizza', 'loki', 'loki eat', 'loki tall',\n",
       "       'pizza', 'talha', 'talha boy', 'tall', 'thor', 'thor eat'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform(['Talha eat pizza']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform(['Thor eat pizza']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "corpus2 = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    "     'Talha is a friend of abu huaraira'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def preprocess(text0):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text0)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        # print(filtered_tokens)\n",
    "    \n",
    "    return \" \".join(filtered_tokens)\n",
    "    # return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document',\n",
       " 'document second document',\n",
       " '',\n",
       " 'document',\n",
       " 'Talha friend abu huaraira']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corpus_processed0 = [\n",
    "#     preprocess(text0) for text0 in corpus2\n",
    "# ]\n",
    "\n",
    "\n",
    "corpus_processed0 = []\n",
    "for text0 in corpus2:\n",
    "    processed_text = preprocess(text0)\n",
    "    corpus_processed0.append(processed_text)\n",
    "corpus_processed0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': 1, 'second': 4, 'talha': 5, 'friend': 2, 'abu': 0, 'huaraira': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['abu', 'document', 'friend', 'huaraira', 'second', 'talha'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer()\n",
    "\n",
    "# X = v.fit_transform(corpus2)\n",
    "X = v.fit_transform(corpus_processed0)\n",
    "print(v.vocabulary_)\n",
    "v.get_feature_names_out()\n",
    "# 'Talha is a friend of abu-huaraira'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0]\n",
      " [0 2 0 0 1 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [1 0 1 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.toarray())\n",
    "X.shape # here vocabulary=6 therefore 6 columns and no of starements is 5 therefore 5 rows hence the  shape is (5,6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform(['talha is friend']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12695, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12690</th>\n",
       "      <td>Coach Shakes Hands Of Imaginary Players After ...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12691</th>\n",
       "      <td>This Minivan-Sized Sea Sponge Is Thought To Be...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692</th>\n",
       "      <td>RECAP: Dramatic Eclipse Photos Don't miss the ...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12693</th>\n",
       "      <td>Richard Sherman Wants To Talk About Police Sho...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12694</th>\n",
       "      <td>Your Customers Ignore Your Emails -- How Will ...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category\n",
       "12690  Coach Shakes Hands Of Imaginary Players After ...    SPORTS\n",
       "12691  This Minivan-Sized Sea Sponge Is Thought To Be...   SCIENCE\n",
       "12692  RECAP: Dramatic Eclipse Photos Don't miss the ...   SCIENCE\n",
       "12693  Richard Sherman Wants To Talk About Police Sho...    SPORTS\n",
       "12694  Your Customers Ignore Your Emails -- How Will ...  BUSINESS"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('news_dataset.json')\n",
    "print(df.shape)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BUSINESS    4254\n",
       "SPORTS      4167\n",
       "CRIME       2893\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 1381 # we have these many SCIENCE articles and SCIENCE is our minority class\n",
    "\n",
    "\n",
    "df_business = df[df.category==\"BUSINESS\"].sample(min_samples, random_state=2022)\n",
    "df_sports = df[df.category==\"SPORTS\"].sample(min_samples, random_state=2022)\n",
    "df_crime = df[df.category==\"CRIME\"].sample(min_samples, random_state=2022)\n",
    "df_science = df[df.category==\"SCIENCE\"].sample(min_samples, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BUSINESS    1381\n",
       "SPORTS      1381\n",
       "CRIME       1381\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_business,df_sports,df_crime,df_science],axis=0)  #axis=0 --> row wise axis=1--> column wise\n",
    "df_balanced.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watching Schrödinger's Cat Die University of C...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WATCH: Freaky Vortex Opens Up In Flooded Lake</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entrepreneurs Today Don't Need a Big Budget to...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These Roads Could Recharge Your Electric Car A...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Civilian 'Guard' Fires Gun While 'Protecting' ...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trump Pays Penalty For Ethically Questionable ...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LIVE: Argentina vs. Iran</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9 Tips for Making Your Blog Better in 2015 New...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Man Arrested Over Threats To CNN:  'Fake News....</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Here's Why Coffee Makes You Have To Poop It hi...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Watching Schrödinger's Cat Die University of C...   SCIENCE\n",
       "1     WATCH: Freaky Vortex Opens Up In Flooded Lake    SCIENCE\n",
       "2  Entrepreneurs Today Don't Need a Big Budget to...  BUSINESS\n",
       "3  These Roads Could Recharge Your Electric Car A...  BUSINESS\n",
       "4  Civilian 'Guard' Fires Gun While 'Protecting' ...     CRIME\n",
       "5  Trump Pays Penalty For Ethically Questionable ...  BUSINESS\n",
       "6                          LIVE: Argentina vs. Iran     SPORTS\n",
       "7  9 Tips for Making Your Blog Better in 2015 New...  BUSINESS\n",
       "8  Man Arrested Over Threats To CNN:  'Fake News....     CRIME\n",
       "9  Here's Why Coffee Makes You Have To Poop It hi...   SCIENCE"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new=df.head(10)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Watching Schrödinger's Cat Die University of C...\n",
       "1       WATCH: Freaky Vortex Opens Up In Flooded Lake \n",
       "2    Entrepreneurs Today Don't Need a Big Budget to...\n",
       "3    These Roads Could Recharge Your Electric Car A...\n",
       "4    Civilian 'Guard' Fires Gun While 'Protecting' ...\n",
       "5    Trump Pays Penalty For Ethically Questionable ...\n",
       "6                            LIVE: Argentina vs. Iran \n",
       "7    9 Tips for Making Your Blog Better in 2015 New...\n",
       "8    Man Arrested Over Threats To CNN:  'Fake News....\n",
       "9    Here's Why Coffee Makes You Have To Poop It hi...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# def process(text):\n",
    "#     # remove stop words and lemmatize the text\n",
    "#     doc = nlp(text)\n",
    "#     filtered_tokens = []\n",
    "#     for token in doc:\n",
    "#         if token.is_stop or token.is_punct:\n",
    "#             continue\n",
    "#         filtered_tokens.append(token.lemma_)\n",
    "#         # print(filtered_tokens)\n",
    "    \n",
    "#     return \" \".join(filtered_tokens)\n",
    "#     # return filtered_tokens\n",
    "\n",
    "corpus_new=df_new.text\n",
    "# process(corpus_new)\n",
    "corpus_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'watching': 177, 'schrödinger': 147, 'cat': 27, 'die': 44, 'university': 167, 'of': 117, 'california': 22, 'berkeley': 14, 'physicists': 128, 'have': 79, 'for': 66, 'the': 156, 'first': 61, 'time': 160, 'showed': 148, 'that': 155, 'in': 85, 'fact': 57, 'it': 89, 'possible': 131, 'to': 162, 'follow': 65, 'metaphorical': 105, 'through': 159, 'whole': 180, 'process': 133, 'whether': 178, 'he': 80, 'lives': 98, 'or': 122, 'dies': 45, 'end': 53, 'watch': 176, 'freaky': 67, 'vortex': 172, 'opens': 121, 'up': 168, 'flooded': 63, 'lake': 93, 'entrepreneurs': 54, 'today': 163, 'don': 48, 'need': 111, 'big': 17, 'budget': 19, 'start': 151, 'wasn': 175, 'so': 150, 'many': 104, 'years': 183, 'ago': 4, 'starting': 152, 'new': 112, 'commerce': 35, 'business': 20, 'on': 120, 'internet': 86, 'was': 174, 'complex': 36, 'custom': 41, 'development': 43, 'project': 135, 'usually': 170, 'costing': 38, 'million': 108, 'dollars': 47, 'more': 110, 'now': 116, 'you': 184, 'can': 25, 'do': 46, 'free': 68, 'these': 157, 'roads': 145, 'could': 39, 'recharge': 140, 'your': 185, 'electric': 52, 'car': 26, 'as': 10, 'drive': 51, 'high': 82, 'tech': 154, 'highways': 83, 'just': 91, 'might': 106, 'change': 30, 'game': 71, 'ev': 56, 'road': 144, 'trips': 165, 'civilian': 31, 'guard': 75, 'fires': 60, 'gun': 77, 'while': 179, 'protecting': 136, 'recruiting': 141, 'center': 28, 'volunteer': 171, 'guards': 76, 'been': 13, 'kicked': 92, 'off': 118, 'grounds': 74, 'outside': 124, 'military': 107, 'lancaster': 94, 'ohio': 119, 'after': 2, 'trump': 166, 'pays': 126, 'penalty': 127, 'ethically': 55, 'questionable': 138, 'political': 129, 'donation': 49, 'came': 24, 'florida': 64, 'attorney': 12, 'general': 72, 'considering': 37, 'joining': 90, 'lawsuit': 96, 'against': 3, 'profit': 134, 'school': 146, 'live': 97, 'argentina': 8, 'vs': 173, 'iran': 88, 'tips': 161, 'making': 102, 'blog': 18, 'better': 15, '2015': 1, 'year': 182, 'outlook': 123, 'flipping': 62, 'calendar': 21, 'from': 70, '2014': 0, 'gives': 73, 'us': 169, 'all': 5, 'chance': 29, 'reboot': 139, 'and': 6, 'rethink': 142, 'why': 181, 'not': 115, 'take': 153, 'fresh': 69, 'look': 100, 'at': 11, 'here': 81, 'are': 7, 'nine': 114, 'll': 99, 'put': 137, 'right': 143, 'track': 164, 'beyond': 16, 'man': 103, 'arrested': 9, 'over': 125, 'threats': 158, 'cnn': 32, 'fake': 58, 'news': 113, 'coming': 34, 'down': 50, 'has': 78, 'zero': 186, 'days': 42, 'since': 149, 'president': 132, 'last': 95, 'called': 23, 'coffee': 33, 'makes': 101, 'poop': 130, 'hits': 84, 'few': 59, 'minutes': 109, 'into': 87, 'cup': 40}\n"
     ]
    }
   ],
   "source": [
    "v = CountVectorizer()\n",
    "\n",
    "# X = v.fit_transform(corpus2)\n",
    "X = v.fit_transform(corpus_new)\n",
    "print(v.vocabulary_)\n",
    "# v.get_feature_names_out()\n",
    "\n",
    "# 'Talha is a friend of abu-huaraira'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform(['schrödinger is cat die']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
